"""
Loads a pre-trained model that can either be used as a solver for arithmetic, 
algebraic or boolean expressions.
"""
import torch
from torch.utils.data import Dataset
import torch.nn.functional as F

from src.config.config import Config
from src.config.config import init_config
from src.modules.model import MLPMixer
from src.modules.model import ConvMixer
from src.modules.model import ConvModel
from src.modules.model import Transformer
from src.utils.tools import load_checkpoint
from src.utils.tools import set_random_seed
from src.utils.tools import count_model_parameters
from src.dataloader import get_dataloader


class Calculator:
    """Chat class.

    Uses a autoregressive model to generate text provided a prompt.

    Attributes:
        model: An autoregressive model.
        dataset: Dataset model has been trained on.
        config: Configuration.
        valid_characters: Legal characters.

    """

    def __init__(
        self,
        model: torch.nn.Module,
        dataset: Dataset,
        config: Config,
    ) -> None:
        """Initializes chat class."""
        self.model = model
        self.dataset = dataset
        self.config = config

        self.valid_characters = list(self.dataset.char_to_index)
        print(f"{self.valid_characters = }")
        exit()

        self.device = self.config.trainer.device
        self.input_sequence_length = self.dataset.max_input_length
        self.do_sample = args.do_sample

    @torch.no_grad()
    def _generate(self, prompt: str) -> str:
        """Generates text from prompt.

        Args:
            input_text: Prompt text.

        Returns:
            Text generated by model.
        """
        # Encode input characters as integer using lookup table from dataloader.
        data = [self.dataset.char_to_index[char] for char in prompt]

        # Create input tensor from encoded characters.
        x = torch.tensor(data=data, dtype=torch.long)[None, ...].to(self.device)

        # Generate some tokens
        for _ in range(self.num_tokens):
            # Make sure that the sequence length is smaller than max sequence length.
            sequence = (
                x
                if x.size(-1) <= self.input_sequence_length
                else x[:, -self.input_sequence_length :]
            )

            # Feed sequence into model.
            logits = self.model(sequence)

            # High temperature: make model more creative (text generation).
            # Low temperature: make model more confident (knowledge retrieval).
            # Take first prediction (0) as it is probably associated with the
            # highest confidence.
            logits = logits[:, self.idx_max_confidence, :] / self.temperature

            # Convert logits to probabilities.
            probabilities = F.softmax(input=logits, dim=-1)

            # TODO: Use argmax.
            _, index_next_token = torch.topk(probabilities, k=1, dim=-1)

            # Add index of most likely token to running sequence.
            x = torch.cat((x, index_next_token), dim=-1)

        # Remove prompt from sequence:
        x = x[:, len(prompt) :]

        output = "".join([self.dataset.index_to_char[int(index)] for index in x[0]])

        return output

    def _is_valid_prompt(self, prompt: str) -> bool:
        """Checks if input prompt contains any illegal characters."""
        for character in prompt:
            if character not in self.valid_characters:
                print(f"\nCharacter '{character}' was not part of the training data.")
                return False
        return True

    def _add_padding(self, prompt: str, char: str = " ") -> str:
        """Pads input prompt to have correct size."""
        multpr = self.input_sequence_length // len(prompt) + 1
        prompt = multpr * (" " + prompt)
        prompt = prompt[-self.input_sequence_length :]
        return prompt

    def test(self):
        """Tests model with some simple prompts."""

        prompts = [
            "(1+2)-3+5",
            "2+(1+2)-4+1",
            "(4-(3-4)+(4+9))",
        ]

        for prompt in prompts:
            print(f"\n>>>\n{prompt}\n")
            if self._is_valid_prompt(prompt=prompt):
                prompt = self._add_padding(prompt=prompt)
                output = self._generate(prompt=prompt)
                print(f"\n>>>\n{output}\n")

    def run(self):
        """Runs chat."""
        is_running = True

        print("\nPlease enter a prompt.\n")

        while is_running:
            print("[User]")
            prompt = input()

            if prompt.startswith("!"):
                command = prompt[1:]
                if command == "exit":
                    is_running = False
                else:
                    print(f"Command '{command}' not recognized.")
                continue
            elif prompt == "":
                continue

            # Feed expression to model
            if is_running and self._is_valid_prompt(prompt=prompt):
                prompt = self._add_padding(prompt=prompt)
                output = self._generate(prompt=prompt)
                print(f"\n[ChatMixer]\n{output}\n")

        print("Bye!")


if __name__ == "__main__":
    # Get configuration file.
    config = init_config(file_path="config.yml")

    # Seed random number generator.
    set_random_seed(seed=config.random_seed)

    # Get dataloader.
    dataloader = get_dataloader(config=config)

    # Get the model.
    model_type = config.model.type
    if model_type == "convmixer":
        model = ConvMixer(config=config)
    elif model_type == "cnn":
        model = ConvModel(config=config)
    elif model_type == "mlpmixer":
        model = MLPMixer(config=config)
    elif model_type == "transformer":
        model = Transformer(config=config)
    else:
        raise NotImplementedError(f"Model type {model_type} not available.")

    count_model_parameters(model=model)
    model.to(config.trainer.device)
    model = torch.jit.script(model)

    ckpt_dir = config.dirs.weights
    model_name = config.load_model.model_name
    load_checkpoint(model=model, ckpt_dir=ckpt_dir, model_name=model_name)
    model.to(config.trainer.device)
    model.eval()

    calc = Calculator(model=model, dataset=dataset, config=config, args=args)
    calc.test()
    calc.run()
